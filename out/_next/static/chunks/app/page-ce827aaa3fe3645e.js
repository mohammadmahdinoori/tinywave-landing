(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[974],{798:(e,t,s)=>{Promise.resolve().then(s.bind(s,8813))},8813:(e,t,s)=>{"use strict";s.r(t),s.d(t,{default:()=>_});var i=s(5155),a=s(6408),r=s(2115);function l(){return(0,i.jsxs)("header",{className:"flex flex-col items-center justify-center text-center py-20 px-6 md:px-12",children:[(0,i.jsx)("div",{className:"h-16"}),(0,i.jsx)("h1",{className:"text-2xl md:text-6xl font-bold text-black max-w-6xl leading-[1.25]",children:"Training Efficient Speech-to-Speech Models via Knowledge Distillation"}),(0,i.jsx)("p",{className:"text-lg text-gray-700 mt-8 max-w-2xl",children:"Developing and providing state-of-the-art efficient speech-to-speech AI models."}),(0,i.jsx)("a",{href:"https://huggingface.co/tinywave",target:"_blank",rel:"noopener noreferrer",children:(0,i.jsx)("button",{className:"mt-8 bg-black text-white rounded-[100px] px-8 py-2 hover:bg-gray-800",children:"Try Our Models"})})]})}function o(){let[e,t]=(0,r.useState)(!1);return(0,r.useEffect)(()=>{t(!0)},[]),(0,i.jsx)(a.P.header,{initial:{y:-100,opacity:0},animate:{y:0,opacity:1},transition:{duration:.3,ease:"easeInOut"},className:"fixed top-0 left-0 right-0 z-50 bg-white/75 backdrop-blur-sm border-b border-gray-200/75 shadow-sm",children:(0,i.jsx)("div",{className:"mx-auto px-6 md:px-12 py-4",children:(0,i.jsxs)("div",{className:"flex flex-col md:flex-row md:items-center md:justify-between gap-2",children:[(0,i.jsx)("div",{className:"flex-1",children:(0,i.jsx)("h1",{className:"text-lg md:text-xl font-bold text-gray-900",children:"TinyWave"})}),(0,i.jsx)("div",{className:"flex text-right overflow-hidden",children:(0,i.jsxs)("p",{className:"text-sm md:text-base text-gray-600 whitespace-nowrap overflow-hidden overflow-ellipsis",children:[(0,i.jsx)("span",{className:"font-medium",children:"Authors:"})," ",(0,i.jsx)("span",{className:"italic",children:"Mohammadmahdi Nouriborji, Morteza Rohanian"})]})})]})})})}function n(){return(0,i.jsx)("section",{id:"models",className:"bg-white",children:(0,i.jsxs)("div",{className:"w-full mx-auto flex flex-col items-center md:flex-row bg-gray-100 px-8 py-16",children:[(0,i.jsxs)("div",{className:"max-w-6xl w-full md:w-1/2 md:pl-16 text-center md:text-left",children:[(0,i.jsx)("h2",{className:"text-4xl font-bold text-black",children:"Abstract"}),(0,i.jsx)("p",{className:"text-gray-700 mt-6 text-justify",children:"Current speech language models deliver strong results but remain too large for many deployment settings.  We present TinyWave, a family of 2 B-parameter speech-to-speech transformers.  A layer-aligned distillation strategy—matching hidden states, attention maps, and softened logits—shrinks model size by 3 \xd7 while retaining most of the teacher’s behaviour.  Trained on 50 k h of publicly available speech, TinyWave supports (i) speech-only generation with either phonetic or expressive token streams and (ii) mixed speech–text continuations. This approach reduces inference latency and memory footprint by 3x compared to the teacher, while preserving expressive qualities such as prosody, intonation, and speaker-specific traits. On Libri-Light language-modeling, TinyWave keeps within 1.4 normalised-perplexity points of its teacher; on spoken StoryCloze and SALMon it preserves 93–97 % of teacher accuracy and surpasses size-matched baselines. Finetuning interleaved models further yields competitive ASR and TTS performance, demonstrating effective Multimodal feature transfer.  These models are optimized for deployment on commodity hardware, enabling applications in real-time conversational agents, assistive technologies, and low-resource environments. We release models, training code, and evaluation scripts to facilitate reproducible research on compact, expressive speech generation."}),(0,i.jsxs)("div",{className:"mt-8 flex flex-col sm:flex-row justify-center md:justify-start",children:[(0,i.jsx)("a",{href:"https://huggingface.co/tinywave",target:"_blank",rel:"noopener noreferrer",children:(0,i.jsx)("button",{className:"bg-black text-white rounded-full px-8 py-2",children:"Download Models"})}),(0,i.jsx)("button",{className:"mt-4 sm:mt-0 sm:ml-4 bg-gray-300 text-black rounded-full px-8 py-2",children:"Read Paper"})]})]}),(0,i.jsx)("div",{className:"w-full md:w-1/2 flex justify-center items-center md:px-16 mt-8 md:mt-0",children:(0,i.jsx)("img",{src:"images/architecture.png",alt:"Model Architecture",className:"rounded-xl w-full"})})]})})}var d=s(3540),c=s(782),p=s(4754),m=s(6025),x=s(2071),u=s(6378),h=s(4683),y=s(9343);let v=[{name:"GSLM",sStoryCloze:53.3,tStoryCloze:66.6,sWuggy:64.8,sBlimp:54.2},{name:"TWIST",sStoryCloze:55.4,tStoryCloze:76.4,sWuggy:74.5,sBlimp:59.2},{name:"SpiritLM-Base",sStoryCloze:60.3,tStoryCloze:82.1,sWuggy:70.98,sBlimp:58.37},{name:"TinyWave‑Base (2 B)",sStoryCloze:55.3,tStoryCloze:74.8,sWuggy:70.26,sBlimp:58.08},{name:"Baseline (2 B)",sStoryCloze:53.6,tStoryCloze:53.6,sWuggy:void 0,sBlimp:void 0},{name:"SpiritLM-Expressive",sStoryCloze:57.1,tStoryCloze:75.5,sWuggy:65,sBlimp:54.35},{name:"TinyWave‑Expressive",sStoryCloze:54.1,tStoryCloze:71.6,sWuggy:63.98,sBlimp:54.28},{name:"Baseline‑Expressive",sStoryCloze:50.6,tStoryCloze:63.1,sWuggy:void 0,sBlimp:void 0}];function f(){return(0,i.jsxs)("section",{id:"benchmark",className:"py-16 px-6 md:px-12 bg-black text-white",children:[(0,i.jsxs)("div",{className:"max-w-6xl mx-auto text-center",children:[(0,i.jsx)("h2",{className:"text-5xl font-bold text-white bg-clip-text text-transparent",children:"Spoken‑LM Benchmarks"}),(0,i.jsx)("p",{className:"text-gray-400 mt-4 max-w-3xl mx-auto",children:"Accuracy (↑) across sStoryCloze, tStoryCloze, sWuggy, and sBlimp."})]}),(0,i.jsx)("div",{className:"mt-10 max-w-6xl mx-auto",children:(0,i.jsx)(d.u,{width:"100%",height:500,children:(0,i.jsxs)(c.E,{data:v,margin:{top:20,right:30,left:20,bottom:50},children:[(0,i.jsx)(p.d,{strokeDasharray:"3 3",stroke:"#444"}),(0,i.jsx)(m.W,{dataKey:"name",stroke:"#bbb",interval:0,angle:-35,textAnchor:"end",height:80}),(0,i.jsx)(x.h,{stroke:"#bbb",domain:[50,85]}),(0,i.jsx)(u.m,{wrapperStyle:{backgroundColor:"#222",borderRadius:"8px",color:"white"}}),(0,i.jsx)(h.s,{wrapperStyle:{color:"white",bottom:0}}),(0,i.jsx)(y.y,{dataKey:"sStoryCloze",fill:"#e91e63",name:"sStoryCloze (%)"}),(0,i.jsx)(y.y,{dataKey:"tStoryCloze",fill:"#ff9800",name:"tStoryCloze (%)"}),(0,i.jsx)(y.y,{dataKey:"sWuggy",fill:"#00bcd4",name:"sWuggy (%)"}),(0,i.jsx)(y.y,{dataKey:"sBlimp",fill:"#4caf50",name:"sBlimp (%)"})]})})})]})}var g=s(760),w=s(2545),b=s(1289);function j(e){let{examples:t,sectionTitle:s="Model Examples",sectionDescription:l="Experience our state-of-the-art model with real-time voice input and high-quality output."}=e,[o,n]=(0,r.useState)(0),d=t[o];return(0,i.jsxs)("section",{className:"bg-gray-100 text-black py-16 px-6 md:px-12",children:[(0,i.jsxs)("div",{className:"max-w-6xl mx-auto text-center mb-12",children:[(0,i.jsx)("h2",{className:"text-4xl font-bold",children:s}),(0,i.jsx)("p",{className:"mt-4 text-lg text-gray-600",children:l})]}),(0,i.jsxs)("div",{className:"max-w-6xl mx-auto flex flex-col md:flex-row gap-8 items-center",children:[(0,i.jsx)("div",{className:"md:w-1/2 w-full flex justify-center",children:(0,i.jsx)(g.N,{mode:"wait",children:(0,i.jsx)(a.P.div,{initial:{opacity:0,x:30},animate:{opacity:1,x:0},exit:{opacity:0,x:-30},transition:{duration:.3},className:"w-full bg-gray-200 px-8 py-16 mx-4 rounded-xl relative",children:(0,i.jsxs)("div",{className:"space-y-8",children:[""!==d.userAudioURL?(0,i.jsxs)("div",{children:[(0,i.jsx)("p",{className:"text-black text-center mb-2 font-bold",children:"Model Input"}),(0,i.jsx)(N,{audioURL:d.userAudioURL})]}):null,(0,i.jsxs)("div",{children:[(0,i.jsxs)("div",{className:"flex flex-row justify-center items-center mb-2",children:[(0,i.jsx)(b.A,{width:16,height:16,fill:"currentColor"}),(0,i.jsx)("p",{className:"text-black font-bold ml-2",children:"Model Output"})]}),(0,i.jsx)(N,{audioURL:d.modelAudioURL})]})]})},d.id)})}),(0,i.jsx)("div",{className:"md:w-1/2 w-full flex flex-col justify-center",children:(0,i.jsx)("div",{className:"space-y-6",children:t.map((e,t)=>(0,i.jsxs)("button",{onClick:()=>n(t),className:"relative block w-full text-left p-4 rounded-md transition-colors ".concat(t===o?"bg-black text-white":"bg-gray-200 hover:bg-gray-300 text-black"),children:[(0,i.jsx)("span",{className:"absolute top-3 right-3 inline-block text-[10px] font-semibold px-2 py-1 rounded-full lowercase ".concat(t===o?"bg-white text-black":"bg-black text-white"),children:e.sampleType}),(0,i.jsx)("h4",{className:"text-xl font-semibold",children:e.title}),(0,i.jsx)("p",{className:"text-sm mt-2",children:e.transcript})]},e.id))})})]})]})}function N(e){let{audioURL:t}=e,s=(0,r.useRef)(null),a=(0,r.useRef)(null),[l,o]=(0,r.useState)(!1);return(0,r.useEffect)(()=>{if(s.current)return a.current=w.A.create({container:s.current,waveColor:"#888",progressColor:"#555",cursorColor:"#ff5722",barWidth:2,height:60}),a.current.load(t),()=>{try{var e;null==(e=a.current)||e.destroy()}catch(e){console.error("Error destroying WaveSurfer:",e)}}},[t]),(0,i.jsxs)("div",{className:"bg-gray-100 p-4 rounded-lg",children:[(0,i.jsx)("div",{ref:s,className:"w-full"}),(0,i.jsx)("button",{onClick:()=>{a.current&&(a.current.playPause(),o(e=>!e))},className:"mt-2 px-4 py-2 bg-gray-200 text-black rounded hover:bg-gray-300 transition",children:l?"Pause":"Play"})]})}function k(){return(0,i.jsx)("footer",{className:"bg-black text-white text-center py-4",children:(0,i.jsx)("p",{className:"text-sm",children:"\xa9 2025 Tinywave. All rights reserved."})})}let S={hidden:{opacity:0,y:50},visible:{opacity:1,y:0}},T="https://mohammadmahdinoori.github.io/tinywave-landing",A=[{id:1,title:"Example 1",sampleType:"text-to-speech",transcript:"Input (Text): She had never seen the ocean before, and when she finally stood at the shore—",userAudioURL:"",modelAudioURL:T+"/audio/tinywave-expressive/prompt_1.wav"},{id:2,title:"Example 2",sampleType:"text-to-speech",transcript:"Input (Text): You think this is funny? Do you have any idea what you’ve done?",userAudioURL:"",modelAudioURL:T+"/audio/tinywave-expressive/prompt_2.wav"},{id:3,title:"Example 3",sampleType:"speech-to-speech",transcript:"Input (Speech): He rose from his chair and",userAudioURL:T+"/audio/tinywave-expressive/prompt_3_input.wav",modelAudioURL:T+"/audio/tinywave-expressive/prompt_3_output.wav"},{id:4,title:"Example 4",sampleType:"speech-to-speech",transcript:"Input (Speech): The keen wind",userAudioURL:T+"/audio/tinywave-expressive/prompt_7_input.wav",modelAudioURL:T+"/audio/tinywave-expressive/prompt_7_output.wav"},{id:5,title:"Example 5",sampleType:"text-to-speech",transcript:'Input (Text): "You don’t understand. If we do this—", "Then we can’t go back. I know."',userAudioURL:"",modelAudioURL:T+"/audio/tinywave-expressive/prompt_4.wav"},{id:6,title:"Example 6",sampleType:"text-to-speech",transcript:"Input (Text): I tried so hard to make it work, but—",userAudioURL:"",modelAudioURL:T+"/audio/tinywave-expressive/prompt_5.wav"},{id:7,title:"Example 7",sampleType:"text-to-speech",transcript:"Input (Text): I thought it was a dream, but when I woke up—",userAudioURL:"",modelAudioURL:T+"/audio/tinywave-expressive/prompt_8.wav"}],C=[{id:1,title:"Example 1",sampleType:"speech-to-speech",transcript:"Input (Speech): Many little pieces of silver",userAudioURL:T+"/audio/tinywave-base/prompt_1_input.wav",modelAudioURL:T+"/audio/tinywave-base/prompt_1_output.wav"},{id:2,title:"Example 2",sampleType:"speech-to-speech",transcript:"Input (Speech): He would see however that there was",userAudioURL:T+"/audio/tinywave-base/prompt_2_input.wav",modelAudioURL:T+"/audio/tinywave-base/prompt_2_output.wav"},{id:3,title:"Example 3",sampleType:"speech-to-speech",transcript:"Input (Speech): 1734",userAudioURL:T+"/audio/tinywave-base/prompt_3_input.wav",modelAudioURL:T+"/audio/tinywave-base/prompt_3_output.wav"}];function _(){return(0,i.jsxs)("div",{className:"bg-white",children:[(0,i.jsx)(o,{}),(0,i.jsx)(a.P.div,{id:"hero",initial:"hidden",whileInView:"visible",viewport:{once:!0},variants:S,transition:{duration:.5,ease:"easeOut"},children:(0,i.jsx)(l,{})}),(0,i.jsx)(a.P.div,{id:"flow",initial:"hidden",whileInView:"visible",viewport:{once:!0},variants:S,transition:{duration:.5,delay:.1,ease:"easeOut"},children:(0,i.jsx)(n,{})}),(0,i.jsx)(a.P.div,{initial:"hidden",whileInView:"visible",viewport:{once:!0},variants:S,transition:{duration:.5,delay:.2,ease:"easeOut"},children:(0,i.jsx)(f,{})}),(0,i.jsxs)(a.P.div,{initial:"hidden",whileInView:"visible",viewport:{once:!0},variants:S,transition:{duration:.5,delay:.2,ease:"easeOut"},children:[(0,i.jsx)(j,{examples:A,sectionTitle:"TinyWave Expressive",sectionDescription:"Examples from our interleaved expressive model."}),(0,i.jsx)(j,{examples:C,sectionTitle:"TinyWave Base",sectionDescription:"Examples from our speech-to-speech base model."})]}),(0,i.jsx)(k,{})]})}}},e=>{var t=t=>e(e.s=t);e.O(0,[94,441,684,358],()=>t(798)),_N_E=e.O()}]);